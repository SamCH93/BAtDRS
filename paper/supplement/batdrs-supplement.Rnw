\documentclass[a4paper, 11pt]{article}
\usepackage[dvipsnames]{xcolor}
\input{header.tex}

\begin{document}
\maketitle


<< "main-setup", echo = FALSE, message = FALSE, warning = FALSE >>=
##  knitr options
library(knitr)
opts_chunk$set(fig.height = 4,
               echo = FALSE,
               warning = FALSE,
               message = FALSE,
               cache = TRUE,
               eval = TRUE)

## should sessionInfo be printed at the end?
reproducibility <- TRUE

## set digits printed
options(scipen = 10)

## CRAN packages
## -----------------------------------------------------------------------------
library(ReplicationSuccess)
library(dplyr)
library(tidyr)
library(ggplot2)
library(scales)
library(colorspace)
library(ggpubr)

## non-CRAN packages
## -----------------------------------------------------------------------------
## remotes::install_gitlab(repo = "samuel.pawel/BayesRep", subdir = "pkg",
##                         host = "gitlab.uzh.ch")
library(BayesRep)
## remotes::install_github(repo = "SamCH93/BayesRepDesign")
library(BayesRepDesign)

## function to format p-values
formatPval. <- function(p, digits = 2) {
    if (is.na(p)) {
        pForm <- NA
    } else if (p < 0.0001) {
        pForm <- "< 0.0001"
    } else {
        pForm <- format(x = p, digits = 2, scientific = FALSE)
    }
    return(pForm)
}
formatPval <- Vectorize(FUN = formatPval.)

## data
protzko <- read.csv("../../data/protzko2020.csv")
protzkolong <- read.csv("../../data/protzko2020long.csv")
@

In this document we provide additional information on computing the predictive
distribution of the replication effect estimate when a prior is assigned to the
heterogeneity variance $\tau^{2}$ (Section~\ref{sec:priortau}). We also provide
additional information on methods for analyzing replication data. For each
method we derive the \emph{success region} in terms of the effect estimate of
the replication study $\that_{r}$, which is required for sample size
determination as illustrated in the main manuscript (Section~\ref{sec:2TR}
to~\ref{sec:BFs}). For the two-trials rule and the replication Bayes factor
methods we additionally provide derivations on how these methods can be
generalized to the multisite replication setting. We show then how the optimal
number of samples per site can be derived for multisite SSD
(Section~\ref{sec:multi}). Finally, we show SSD for the \citet{Protzko2020}
project but using an adaptive shrinkage prior instead of the flat prior as in
the main manuscript (Section~\ref{sec:ssdprotzko}).

\section{Prior on the heterogeneity variance}
\label{sec:priortau}
When also a prior is assigned to the heterogeneity variance $\tau^{2}$, the
predictive distribution of the replication effect estimate $\that_{r}$ is given
by
\begin{align*}
  f(\that_{r} \given \that_{o}, \sigma_{o}, \sigma_{r})
  &= \int_{0}^{+\infty} f(\that_{r} \given \sigma_{r}, \that_{o}, \sigma_{o},
    \tau^{2}) \,
    f(\tau^{2} \given \that_{o}, \sigma_{o}) \, \text{d}\tau^{2}.
\end{align*}
That is, it is the predictive distribution of the replication effect estimate
$\that_{r}$ integrated with respect to the marginal posterior of $\tau^{2}$
based on the original data $x_{o} = \{\that_{o}, \sigma^{2}_{o}\}$. If the
initial prior for $\theta$ is normal
$\theta \sim \Nor(\mutheta, \sigmatheta^{2})$, and the initial prior for
$\tau^{2}$ has density $f(\tau^{2})$, we have
\begin{align*}
  f(\tau^{2} \given \that_{o}, \sigma_{o})
  &= \int_{-\infty}^{+\infty} f(\theta, \tau^{2} \given \that_{o}, \sigma_{o}) \, \text{d}\theta \\
  &= \frac{\int_{-\infty}^{+\infty} f(\that_{o} \given \theta, \tau^{2}, \sigma^{2}_{o}) \,
    f(\theta \given \tau^{2}) \, f(\tau^{2}) \, \text{d}\theta}{\int_{0}^{+\infty}
    \int_{-\infty}^{+\infty} f(\that_{o} \given \theta_{*}, \tau^{2}_{*}, \sigma^{2}_{o}) \,
    f(\theta_{*} \given \tau^{2}_{*}) \, f(\tau^{2}_{*}) \, \text{d}\theta_{*} \,
    \text{d}\tau^{2}_{*}} \\
  &= \frac{f(\tau^{2}) \int_{-\infty}^{+\infty} \Nor(\that_{o} \given \theta, \tau^{2}
    + \sigma^{2}_{o}) \, \Nor(\theta \given \mutheta, \sigmatheta^{2}) \,\text{d}\theta
    }{\int_{0}^{+\infty} f(\tau^{2}_{*})
    \int_{-\infty}^{+\infty} \Nor(\that_{o} \given \theta_{*}, \tau^{2}_{*} + \sigma^{2}_{o}) \,
    \Nor(\theta_{*} \given \mutheta, \sigmatheta^{2}) \, \text{d}\theta_{*} \,
    \text{d}\tau^{2}_{*}} \\
  &= \frac{f(\tau^{2}) \, \Nor(\that_{o} \given \mutheta, \tau^{2}
    + \sigma^{2}_{o} + \sigmatheta^{2})
    }{\int_{0}^{+\infty} f(\tau^{2}_{*})
    \Nor(\that_{o} \given \mutheta, \tau^{2}_{*} + \sigma^{2}_{o} + \sigmatheta^{2}) \,
    \text{d}\tau^{2}_{*}}.
\end{align*}
To compute the marginal posterior density of $\tau^{2}$ one numerical
integration is hence required. The updating of the prior depends on the distance
between prior mean $\mutheta$ and the original effect estimate $\that_{o}$
relative to the prior variance $\sigmatheta^{2}$ and the squared standard error
$\sigma_{o}^{2}$. If an improper uniform prior is assigned to $\theta$
($\sigmatheta^{2} \to \infty$), the posterior reduces to the prior
\begin{align*}
  \lim_{\sigmatheta^{2} \to \infty} f(\tau^{2} \given \that_{o}, \sigma_{o})
  &= \lim_{\sigmatheta^{2} \to \infty} \frac{f(\tau^{2}) \, \Nor(\that_{o} \given \mutheta, \tau^{2}
    + \sigma^{2}_{o} + \sigmatheta^{2})
    }{\int_{0}^{+\infty} f(\tau^{2}_{*})
    \Nor(\that_{o} \given \mutheta, \tau^{2}_{*} + \sigma^{2}_{o} + \sigmatheta^{2}) \,
    \text{d}\tau^{2}_{*}} \\
  &= \lim_{\sigmatheta^{2} \to \infty}  \int_{0}^{+\infty} \frac{f(\tau^{2})}{f(\tau^{2}_{*})} \,
    \underbrace{\sqrt{\frac{\tau^{2}_{*} + \sigma^{2}_{o} + \sigmatheta^{2}}{\tau^{2} + \sigma^{2}_{o} +
    \sigmatheta^{2}}}}_{\to 1} \, \exp\bigg[-\frac{1}{2}\bigg\{\underbrace{
    \frac{(\that_{o} - \mutheta)^{2}}{\tau^{2} + \sigma^{2}_{o} + \sigmatheta^{2}}}_{\downarrow 0} -
    \underbrace{\frac{(\that_{o} - \mutheta)^{2}}{\tau^{2}_{*} + \sigma^{2}_{o} +
    \sigmatheta^{2}}}_{\downarrow 0} \bigg\}\bigg] \, \text{d}\tau^{2}_{*} \\
  &= f(\tau^{2}),
\end{align*}
the limit can be interchanged with the integral because of the monotone
convergence theorem. This means that with a uniform prior nothing can be learned
about the variance $\tau^{2}$ which intuitively makes sense as estimation of a
variance requires at least two observations. The phenomenon is illustrated in
Figure~\ref{fig:margposttau2} for the data from the experiment ``Labels''
\citep{Protzko2020} as also used in the main manuscript. We see that as the
prior standard deviation increases (making the prior more uniform), the marginal
posterior density becomes closer to the prior density.
\begin{figure}[!htb]
<< "tau-random-example", fig.height = 3.5 >>=
study <- filter(protzkolong, Study == "Labels", Type == "Original")
to <- study$dr
so <- sqrt(study$vr)
dposttau2 <- function(tau2, to, so, mu, sp, priorDens) {
    intFun. <- function(t2) {
        priorDens(t2)*dnorm(x = to, mean = mu, sd = sqrt(so^2 + t2 + sp^2))
    }
    intFun <- Vectorize(FUN = intFun.)
    normConst <- try(integrate(f = intFun, lower = 0, upper = Inf)$value)
    if (inherits(normConst, "try-error")) {
        dens <- rep(NaN, times = length(tau2))
    } else {
        dens <- intFun(tau2)/normConst
    }
    return(dens)
}

## half normal prior on tau implies the following prior on tau^2 (by change of
## variables)
priorsd <- 0.05/sqrt(pi/2) # choose mean of prior to be equal to 0.05
priorDens <- function(tau2, sd = priorsd) dnorm(x = sqrt(tau2), sd = sd)/sqrt(tau2)

## prior on effect size
mu <- 0
sps <- c(0.05, 0.1, 0.15, 0.2, 0.25)

## compute prior/posterior
tauseq <- seq(0, 0.2, length.out = 500)
tau2seq <- tauseq^2
posteriorDF <- do.call("rbind", lapply(X = sps, FUN = function(sp) {
    pdens <- dposttau2(tau2 = tau2seq, to = to, so = so, mu = mu, sp = sp,
                       priorDens = priorDens)
    data.frame(tau2 = tau2seq, tau = tauseq,
               densitytau2 = pdens, densitytau = pdens*2*tauseq,
               sp = sp, mu = mu, to = to, so = so,
               type = "posterior")
}))
priorDF <- data.frame(tau2 = tau2seq, tau = tauseq,
                      densitytau2 = priorDens(tau2 = tau2seq),
                      densitytau = priorDens(tau2 = tau2seq)*2*tauseq,
                      type = "prior")

ggplot(data = posteriorDF, aes(x = tau, y = densitytau, linetype = type)) +
    geom_line(data = priorDF, alpha = 0.95, size = 0.8) +
    geom_line(aes(color = factor(sp, ordered = TRUE), linetype = type),
              alpha = 0.8) +
    labs(x = bquote(tau), y = "Marginal posterior density",
         color = bquote("Prior SD" ~ sigma[theta]),
         linetype = NULL) +
    theme_bw() +
    theme(panel.grid.minor = element_blank())

## ## check that integrates to one
## integrate(f = dposttau2, lower = 0, upper = Inf, to = to, so = so, mu = mu,
##           sp = 10, priorDens = priorDens)
@
\caption{Marginal posterior distribution of heterogeneity variance $\tau^{2}$
  based on data from experiment ``Labels'' from \citet{Protzko2020} with
  original effect estimate $\hat{\theta}_{o} = \Sexpr{round(to, 3)}$ and
  standard error $\sigma_{o} = \Sexpr{round(so, 3)}$. A
  $\theta \sim \Nor(\Sexpr{mu}, \sigmatheta^{2})$ prior is assigned to the
  effect size $\theta$ and a half normal prior with standard deviation
  $\Sexpr{round(priorsd, 3)}$ is assigned to $\tau$.}
\label{fig:margposttau2}
\end{figure}

Combining all the previous results, we obtain the probability of replication
success as
\begin{align*}
  \Pr(\that_{r} \in S \given \that_{o}, \sigma_{o}, \sigma_{r})
  &= \int_{S}\int_{0}^{+\infty} f(\that_{r} \given \that_{o}, \sigma_{o}, \sigma_{r}, \tau^{2}) \,
    f(\tau^{2} \given \that_{o}, \sigma_{o}) \, \text{d}\that_{r} \,\text{d}\tau^{2} \\
  &= \int_{0}^{+\infty} \Pr(\that_{r} \in S \given \that_{o}, \sigma_{o}, \sigma_{r}, \tau^{2}) \,
    f(\tau^{2} \given \that_{o}, \sigma_{o}) \, \text{d}\tau^{2}. \\
\end{align*}
This mean computing the probability of replication success with a prior on
$\tau^{2}$ requires two-dimensional numerical integration. However, in the
common case when a uniform prior is assigned to $\theta$, the marginal posterior
distribution of $\tau^{2}$ reduces to the prior, and only one numerical
integration is required.

\begin{figure}[!htb]
<< "example-applied", fig.height = 3.75 >>=
## ssd parameters
power <- 0.8
levelSig <- 0.025
levelSigMeta <- 0.025^2
levelPs <- levelSceptical(level = 0.025)
confLevel <- 0.9
margin <- 0.2
levelBFr <- 1/10
levelBFs <- 1/10
cseq <- exp(seq(log(1/11), log(11), length.out = 100))
methodLabs <- c("'Two-trials rule'", "'Replication Bayes factor'",
                "'Meta-analysis'", "'Equivalence'",
                "'Skeptical' ~ italic(p) * '-value'",
                "'Skeptical Bayes factor'")

## prior density
fprior <- function(tau2) dnorm(x = sqrt(tau2), sd = priorsd)/sqrt(tau2)

## generic function to compute probability of replication success for random
## tau^2
porstau <- function(sr, to, so, porsfun, priorfun, upper = 3) {
    pRS <- sapply(X = sr, FUN = function(sri) {
        intFun. <- function(tau2) {
            dp <- designPrior(to = to, so = so, tau = sqrt(tau2))
            out <- porsfun(dprior = dp, sr = sri)*priorfun(tau2)
        }
        intFun <- Vectorize(FUN = intFun.)
        ## HACK numerical problems when upper = Inf, for now choose a large value
        res <- try(integrate(f = intFun, lower = 0, upper = upper,
                             rel.tol = .Machine$double.eps^0.7)$value, silent = TRUE)
        if (inherits(res, "try-error")) {
            return(NaN)
        } else {
            return(res)
        }
    })
    return(pRS)
}

porsfun2TR <- function(dprior, sr) {
    porsSig(level = levelSig, dprior = dprior, sr = sr)
}
porsfunBFr <- function(dprior, sr) {
    porsBFr(level = levelBFr, dprior = dprior, sr = sr)
}
porsfunMeta <- function(dprior, sr) {
    porsMeta(level = levelSigMeta, dprior = dprior, sr = sr)
}
porsfunEqu <- function(dprior, sr) {
    porsEqu(level = 1 - confLevel, dprior = dprior, margin = margin, sr = sr)
}
porsfunPs <- function(dprior, sr) {
    porsPs(level = levelPs, dprior = dprior, sr = sr)
}
porsfunBFs <- function(dprior, sr) {
    porsBFs(level = levelBFs, dprior = dprior, sr = sr)
}
porsList <- list(porsfun2TR, porsfunBFr, porsfunMeta, porsfunEqu, porsfunPs,
                 porsfunBFs)
names(porsList) <- methodLabs

plotDF1 <- do.call("rbind", lapply(X = seq(1, length(porsList)), FUN = function(i) {
    data.frame(c = cseq, method = methodLabs[i],
               pow = porstau(sr = sqrt(study$vr/cseq), to = to, so = so,
                             porsfun = porsList[[i]], priorfun = fprior))
}))
plotDF1$facetlab <- paste0('tau ~ "~" ~ "HN(" *', round(priorsd, 3),'* ")"')

## comparison to fixed tau as in main manuscript
tauAbs <- 0.2/(2*qnorm(p = 0.975))
dp <- designPrior(to = to, so = so, tau = tauAbs)
plotDF2 <- do.call("rbind", lapply(X = seq(1, length(porsList)), FUN = function(i) {
    data.frame(c = cseq, method = methodLabs[i],
               pow = porsList[[i]](sr = sqrt(study$vr/cseq), dprior = dp))
}))
plotDF2$facetlab <- paste0('tau ==', round(tauAbs, 2))
plotDF <- rbind(plotDF1, plotDF2)

## plot power curves
cols <- palette.colors(n = length(methodLabs), palette = "Okabe-Ito")
names(cols) <- methodLabs
powbks <- c(0, 20, 40, 60, 80, 100)/100
cbks <- c(1/10, 1/3, 1, 3, 10, 30, 100)
ggplot(data = plotDF, aes(x = c, y = pow, color = method)) +
    facet_wrap(~facetlab, labeller = label_parsed) +
    geom_line(alpha = 0.8, size = 0.65) +
    scale_x_log10(breaks = cbks, labels = formatBF(cbks)) +
    scale_y_continuous(breaks = powbks, labels = scales::label_percent(accuracy = 0.1),
                       limits = c(0, 1)) +
    scale_color_manual(values = cols, labels = scales::parse_format()) +
    labs(x = bquote("Relative sample size" ~ italic(c) == italic(n[r]/n[o])),
         y = "Probability of replication success",
         color = "") +
    theme_bw() +
    theme(legend.position = "top", legend.text = element_text(size = 10),
          panel.grid.minor = element_blank(), legend.text.align = 0)
@
\caption{Probability of replication success as a function of relative sample
  size $c = n_{r}/n_{o}$ for experiment ``Labels'' with original effect estimate
  $\hat{\theta}_{o} = \Sexpr{round(to, 3)}$ and standard error
  $\sigma_{o} = \Sexpr{round(so, 3)}$ for uniform initial prior for effect size
  $\theta$ and either fixed $\tau = \Sexpr{round(tauAbs, 2)}$ (as in main
  manuscript) or half normal prior with standard deviation
  $\Sexpr{round(priorsd, 3)}$ assigned to $\tau$. Replication success is defined
  by the two-trials rule at level $\alpha = \Sexpr{levelSig}$, the replication
  Bayes factor at level $\gamma = 1/\Sexpr{1/levelBFr}$, fixed effects-meta
  analysis at level $\alpha = \Sexpr{sqrt(levelSigMeta)}^{2}$, effect size
  equivalence based on $\Sexpr{confLevel*100}\%$ confidence interval and with
  margin $\Delta = \Sexpr{margin}$, skeptical $p$-value at level
  $\alpha = \Sexpr{round(levelPs, 3)}$, and skeptical Bayes factor at level
  $\gamma = 1/\Sexpr{1/levelBFs}$.}
\label{fig:exampletaurandom}
\end{figure}

Figure~\ref{fig:exampletaurandom} shows the probability of replication success
based on data from the ``Labels'' experiment, as in the main manuscript. A half
normal prior with is assigned to the heterogeneity $\tau$ which is a typical
prior distribution used for heterogeneity modeling in meta-analysis
\citep{Rover2021}. The standard deviation of the prior is set to
$\Sexpr{round(priorsd, 3)}$ so that the mean of the prior equals the value of
the fixed heterogeneity $\tau = 0.05$ elicited in the main manuscript. We see
that the probability of replication success is only slightly higher compared to
the fixed $\tau = 0.05$ from the main manuscript.


\section{The two-trials rule}
\label{sec:2TR}
The two-trials rule is the most common analysis approach for replication
studies. Replication success is declared if both original and replication study
achieve statistical significance at some level $\alpha$ (and both estimates go
in the same direction which can be taken into account by using one-sided
$p$-values). We will study the two-trial under normality using the data model
$\that_{i} \given \theta \sim \Nor(\theta, \sigma^{2}_{i})$ with $\that_{i}$ the
estimate of the unknown effect size $\theta$ from study $i$ and $\sigma_{i}$ is
the corresponding standard error (assumed to be know). The $p$-values for
testing $H_{0} \colon \theta = 0$ versus $H_{1} \colon \theta > 0$ are then
$p_{i} = 1 - \Phi(\that_{i}/\sigma_{i})$ whereas for the alternative
$H_{1} \colon \theta < 0$ they are $p_{i} = \Phi(\that_{i}/\sigma_{i})$. Suppose
the original effect estimate was statistically significant at level $\alpha$,
\ie{} $p_{o} \leq \alpha$. Replication success at level $\alpha$ is then
established if the replication effect estimate $\that_{r}$ is also statistically
significant at level $\alpha$, \ie{} $p_{r} \leq \alpha$. By applying some
algebraic manipulations to the success condition, one can show that this implies
that replication success is achieved if the replication effect estimate
$\that_{r}$ is contained in the success region
\begin{align*}
  S_{\text{2TR}} =
  \begin{cases}
    \left[\zalpha \, \sigma_{r}, \infty \right) & \text{for} ~ \that_{o} > 0 \\
    \left[-\infty, -\zalpha \, \sigma_{r} \right) & \text{for} ~ \that_{o} < 0.
  \end{cases}
\end{align*}

\subsection{The multisite two-trials rule}
If multiple replication studies are conducted for one original study (a
\emph{multisite} replication), the two-trials rule is typically modified by
meta-analyzing the effect estimates from all replications and then using the
combined estimate as usual in the two-trials rule \citep[see \eg{} the ``Many
labs'' projects from][]{Klein2014, Klein2018}. Suppose $m$ replication studies
are conducted and produce $m$ effect estimates $\that_{r1}, \dots, \that_{m}$
with standard errors $\sigma_{r1}, \dots, \sigma_{rm}$. Subsequently, a weighted
average
$\hat{\theta}_{r*} = \{\sum_{i = 1}^{m} \hat{\theta}_{ri}/(\sigma^{2}_{ri} + \tau^{2}_{r})\}\,\sigma_{r*}^{2}$
with standard error
$\sigma_{r*} = 1/\surd\{\sum_{i}^{m}1/(\sigma^{2}_{ri} + \tau^{2}_{r})\}$ can be
computed. If the between-replication heterogeneity variance $\tau^{2}_{r}$ is
set to zero this corresponds to the fixed effects estimate of $\theta$, while
estimating $\tau^{2}_{r}$ from the data corresponds to the random effects
estimate. Replication success at level $\alpha$ is then established if the
replication $p$-value is smaller than $\alpha$, \ie{}
$p_{r*} = 1 - \Phi(\that_{r*}/\sigma_{r*}) \leq \alpha$. With some algebra one
can show that this implies a success region for the weighted average replication
effect estimate $\that_{r*}$ given by
\begin{align*}
  S_{\text{2TR}} =
  \begin{cases}
    \left[\zalpha \, \sigma_{r*}, \infty \right) & \text{for} ~ \that_{o} > 0 \\
    \left[-\infty, -\zalpha \, \sigma_{r*} \right) & \text{for} ~ \that_{o} < 0.
  \end{cases}
\end{align*}

\section{Fixed effects meta-analysis}
Assume again the data model
$\that_{i} \given \theta \sim \Nor(\theta, \sigma^{2}_{i})$ where $\that_{i}$ is
an estimate of the effect size $\theta$ from study $i \in \{o, r\}$ and
$\sigma_{i}$ is the corresponding standard error (assumed to be know). In the
fixed effects meta-analysis approach replicability is assessed in terms of the
pooled effect estimate $\that_{m}$ and standard error $\sigma_{m}$ which are
\begin{align*}
  &\that_{m} =
    \left(\that_{o}/\sigma_{o}^{2} + \that_{r}/\sigma^{2}_{r}\right)\sigma^{2}_{m}&
&\text{and}&                                                                                       &\sigma_{m} = \left(1/\sigma^{2}_{o} + 1/\sigma^{2}_{r}\right)^{-1/2},&
\end{align*}
which are also equivalent to the mean and standard deviation of a posterior
distribution for the effect size $\theta$ based on the data from original and
replication study and an initial flat prior for $\theta$. Fixed effects
meta-analysis is typically used because estimating a heterogeneity variance from
two studies is highly unstable. Replication success at level $\alpha$ is
established if the one-sided meta-analytic $p$-value (in the direction of the
original effect estimate $\that$) is significant at level $\alpha$, \ie{}
$p_{m} = 1 - \Phi(\that_{m}/\sigma_{m}) \leq \alpha$ for $\that_{o} > 0$ and
$p_{m} = \Phi(\that_{m}/\sigma_{m}) \leq \alpha$ for $\that_{o} < 0$.
With some algebraic manipulations one can show that this criterion implies a
success region $S_{\text{MA}}$ for the replication effect estimate $\that_{r}$
given by
\begin{align*}
  \SMA
  =
  \begin{cases}
    [\sigma_{r} \zalpha\sqrt{1 + \sigma^{2}_{r}/\sigma^{2}_{o}} -
      (\that_{o} \sigma^{2}_{r})/\sigma^{2}_{o},   \infty )
    & \text{for} ~ \that_{o} > 0 \\
    (-\infty, -\sigma_{r} \zalpha\sqrt{1 + \sigma^{2}_{r}/\sigma^{2}_{o}} -
      (\that_{o} \sigma^{2}_{r})/\sigma^{2}_{o}]
    & \text{for} ~ \that_{o} < 0.
\end{cases}
\end{align*}


\section{Effect size equivalence}
The effect size equivalence approach \citep{Anderson2016} defines replication
success via compatibility of the effect estimates from both studies. Under
normality we may assume the data model
$\that_{i} \given \theta_{i} \sim \Nor(\theta_{i}, \sigma^{2}_{i})$ for study
$i \in \{o, r\}$, and we are interested in the true effect size difference
$\delta = \theta_{r} - \theta_{o}$. A $(1 - \alpha)$ confidence interval for
$\delta$ is then given by
\begin{align*}
  C_{\alpha} = \left[\that_{r} - \that_{o} - \zalphatwo \sqrt{\sigma^{2}_{r} + \sigma^{2}_{r}},
  \that_{r} - \that_{o} + \zalphatwo \sqrt{\sigma^{2}_{r} + \sigma^{2}_{r}}\right]
\end{align*}
Effect size equivalence is established if the confidence interval is fully
included in an equivalence region $C_{\alpha} \subseteq [-\Delta, \Delta]$ with
$\Delta > 0$ a pre-specified margin. Applying some algebraic manipulations to
the success conditions one can show that the equivalence test replication success
criterion implies a success region $\SEqu$ for the replication estimate
$\that_{r}$ given by
\begin{align*}
  \SEqu
  = \left[\that_{o} - \Delta + \zalphatwo \sqrt{\sigma^{2}_{o} +
  \sigma^{2}_{r}}, \that_{o} + \Delta - \zalphatwo
  \sqrt{\sigma^{2}_{o} + \sigma^{2}_{r}}\right].
\end{align*}



% \section{The \textit{Q}-test}

\section{The replication Bayes factor}
The replication Bayes factor approach uses the replication data $x_{r}$ to
quantify the evidence for the null hypothesis $H_{0}\colon \theta = 0$ relative
to the alternative hypothesis $H_{1} \colon \theta \sim f(\theta \given x_{o})$,
which postulates that the effect size $\theta$ is distributed according to its
posterior distribution based on the original data $x_{o}$. Assume again a normal
model $\that_{i} \given \theta \sim \Nor(\theta, \sigma^{2}_{i})$ with
$\that_{i}$ an estimate of the effect size $\theta$ from study $i \in \{o, r\}$
and $\sigma_{i}$ the corresponding standard error (assumed to be know), and that
we use the alternative $H_{1} \colon \Nor(\that_{o}, \sigma^{2}_{o})$ which
arises from updating an initial flat prior for $\theta$ the original data
$x_{o} = \{\that_{o}, \sigma_{o}\}$. The replication Bayes factor is then
\begin{align}
  \label{eq:bfr}
  \BFr &= \frac{f(\that_{r} \given H_{0})}{f(\that_{r} \given H_{1})}
       = \sqrt{1 + \sigma^{2}_{o}/\sigma^{2}_{r}} \, \exp\left[
         -\frac{1}{2}\left\{ \frac{\that^{2}_{r}}{\sigma^{2}_{r}} -
         \frac{(\that_{r} - \that_{o})^{2}}{\sigma^{2}_{o} + \sigma^{2}_{r}}
         \right\}\right].
\end{align}
Replication success at level $\gamma \in (0, 1)$ is achieved if
$\BFr \leq \gamma$. By applying some algebra to $\BFr \leq \gamma$, one can show
that it is equivalent to the replication effect estimate $\that_{r}$ falling in
the success region
\begin{align*}
  \SBFr
  = \left(-\infty, -\sqrt{A} - (\that_{o}\sigma^{2}_{r})/\sigma^{2}_{o}\right] \bigcup
   \left[\sqrt{A} - (\that_{o}\sigma^{2}_{r})/\sigma^{2}_{o}, \infty\right)
\end{align*}
where
$A = \sigma^{2}_{r}(1 + \sigma^{2}_{r}/\sigma^{2}_{o}) \{\that_{o}^{2}/\sigma^{2}_{o} - 2 \log \gamma + \log(1 + \sigma^{2}_{o}/\sigma^{2}_{r})\}$.

\subsection{The multisite replication Bayes factor}
The generalization of the replication Bayes factor to the multisite setting is
straightforward. The data are represented by vector of replication effect
estimates $\bthat_{r} = (\that_{r1}, \dots, \that_{rm})^{\top}$ with
corresponding standard error vector
$\bsigma_{r} = (\sigma_{r1}, \dots, \sigma_{rm})^{\top}$, and we assume the data
model
$\bthat_{r} \given \theta \sim \Nor_{m}\{\theta \, \bone_{m}, \diag(\bsigma^{2} + \tau^{2}_{r} \, \bone_{m}\}$
where $\bone_{m}$ is a vector of $m$ ones and $\tau^{2}_{r}$ is a heterogeneity
variance for the replication effect sizes (not to be confused with the
heterogeneity variance $\tau^{2}$ used in the design prior).

As in the singlesite case, the replication Bayes factor quantifies the evidence
that the data provide for the null hypothesis $H_{0}\colon \theta = 0$ relative
to the alternative hypothesis
$H_{1} \colon \theta \sim \Nor(\that_{o}, \sigma^{2}_{o})$. The marginal density
of the replication data under the null hypothesis is simply
$\bthat_{r} \given H_{0} \sim \Nor_{m}\{0 \, \bone_{m}, \diag(\bsigma^{2} + \tau^{2}_{r} \, \bone_{m}\}$,
whereas the marginal likelihood under the alternative $H_{1}$ is obtained from
integrating the likelihood
% $\bthat_{r} \given \theta \sim \Nor_{m}\{\theta \, \bone_{m}, \diag(\bsigma^{2} + \tau^{2}_{r} \, \bone_{m}\}$
with respect to the prior distribution of $\theta$ under the alternative
$H_{1}$. % $H_{1} \colon \theta \sim \Nor(\that_{o}, \sigma_{o})$.
Let $\Nor(x;m,v)$ denote the normal density function mean $m$ and variance $v$
evaluated at $x$. Define also
$\hat{\theta}_{r*} = \left\{\sum_{i=1}^{n}\hat{\theta}_{ri}/(\sigma^{2}_{ri} + \tau^{2}_{r})\right\} \sigma^{2}_{r*}$
and
$\sigma^{2}_{r*} = 1/\left\{\sum_{i=1}^{n}1/(\sigma^{2}_{ri} + \tau^{2}_{r})\right\}$,
\ie{} the weighted average of the replication effect estimates based on the
heterogeneity $\tau^{2}_{r}$ and its variance. The marginal density is then

\begin{align*}
        f(\hat{\theta}_{r} \given H_{1})
        &= \int f(\hat{\theta}_{r} \given \theta) f(\theta \given H_{1})
                        \, \text{d}\theta \\
              &= \int \frac{\exp\left[-\frac{1}{2} \left\{\sum_{i=1}^{n} \frac{(\hat{\theta}_{ri} - \theta)^{2}}{\sigma^{2}_{ri} + \tau^{2}_{r}} +
                  \frac{(\theta - \that_{o})^{2}}{\sigma^{2}_{o}}\right\} \right]}{
                                    \left\{2\pi \sigma^{2}_{o} \prod_{i = 1}^{n} 2\pi \left(\sigma^{2}_{ri} + \tau^{2}_{r}\right)\right\}^{1/2}}
    \, \text{d}\theta \\
  &= \int \frac{
    \exp\left[-\frac{1}{2} \left\{\sum_{i=1}^{n} \frac{(\hat{\theta}_{ri} - \hat{\theta}_{r*})^{2}}{\sigma^{2}_{ri} + \tau^{2}_{r}} +  \frac{(\hat{\theta}_{r*} - \theta)^{2}}{\sigma^{2}_{r*}} +
    \frac{(\theta - \that_{o})^{2}}{\sigma^{2}_{o}}\right\} \right]}{
    \left\{2\pi \sigma^{2}_{o} \prod_{i = 1}^{n} 2\pi \left(\sigma^{2}_{ri} + \tau^{2}_{r}\right)\right\}^{1/2}}
    \, \text{d}\theta \\
  &= \frac{\exp\left[-\frac{1}{2} \left\{\sum_{i=1}^{n} \frac{(\hat{\theta}_{ri} - \hat{\theta}_{r*})^{2}}{\sigma^{2}_{ri} + \tau^{2}_{r}}\right\} \right]}{\left\{2\pi \sigma^{2}_{o} \prod_{i = 1}^{n} 2\pi \left(\sigma^{2}_{ri} + \tau^{2}_{r}\right)\right\}^{1/2}}
    \underbrace{\int \exp\left[-\frac{1}{2} \left\{\frac{(\hat{\theta}_{r*} - \theta)^{2}}{\sigma^{2}_{r*}} +
    \frac{(\theta - \that_{o})^{2}}{\sigma^{2}_{o}}\right\} \right] \text{d}\theta}_{= \Nor(\hat{\theta}_{r*}; m, \sigma^{2}_{o} + \sigma^{2}_{r*}) 2\pi \sigma_{o} \sigma_{r*}} \\
  &= \left\{(1 + \sigma^{2}_{o}/\sigma^{2}_{r*}) \prod_{i = 1}^{n} 2\pi \left(\sigma^{2}_{ri} + \tau^{2}_{r}\right)\right\}^{-1/2} \exp\left[-\frac{1}{2}\left\{
    \sum_{i=1}^{n} \frac{(\hat{\theta}_{ri} - \hat{\theta}_{r*})^{2}}{\sigma^{2}_{ri} + \tau^{2}_{r}} + \frac{(\hat{\theta}_{r*} - \that_{o})^{2}}{\sigma^{2}_{r*} + \sigma^{2}_{o}}\right\}\right].
\end{align*}
Dividing the marginal density of $\bthat_{r}$ under $H_{0}$ by the marginal
density of $\bthat_{r}$ under $H_{1}$ leads to cancellation of several terms, and
produces the replication Bayes factor
\begin{align*}
  \BF_{01}(\hat{\theta}_{r})
  &= \frac{f(\hat{\theta}_{r} \given H_{0})}{f(\hat{\theta}_{r} \given H_{1})}
    = \sqrt{1 + \sigma^{2}_{o}/\sigma^{2}_{r*}}  \exp\left[-\frac{1}{2}\left\{
    \frac{\hat{\theta}_{r*}^{2}}{\sigma^{2}_{r*}} -
    \frac{(\hat{\theta}_{r*} - \hat{\theta}_{o})^{2}}{\sigma^{2}_{r*} + \sigma^{2}_{o}}\right\}\right].
\end{align*}
The multisite replication Bayes factor is therefore equivalent to the singlesite
replication Bayes factor from~\eqref{eq:bfr} but using the weighted average
$\that_{r*}$ and its standard error $\sigma_{r*}$ as the replication effect
estimate $\that_{r}$ and standard error $\sigma_{r}$.

\section{The skeptical \textit{p}-value}
\citet{Held2020} proposed a reverse-Bayes approach for assessing replicability.
One assumes again the data model
$\that_{i} \given \theta \sim \Nor(\theta, \sigma^{2}_{i})$ with
$i \in \{o, r\}$, along with a zero-mean ``skeptical'' prior
$\theta \sim \Nor(0, \sigma^{2}_{s})$ for the effect size. In a first step, a
level $\alpha \geq p_{o} = 1 - \Phi(|\that_{o}|/\sigma_{o})$ is fixed and the
``sufficiently skeptical'' prior variance $\sigma^{2}_{s}$ is computed
\begin{align*}
  \sigma^{2}_{s} = \frac{\sigma^{2}_{o}}{(z_{o}^{2}/\zalpha^{2}) - 1}
\end{align*}
where $z_{o} = \that_{o}/\sigma_{o}$. The sufficiently skeptical prior variance
$\sigma^{2}_{s}$ has the property that it renders the resulting posterior of
$\theta$ no longer ``credible'' at level $\alpha$, that is, the posterior tail
probability is fixed to
$\Pr(\theta \geq 0 \given \that_{o}, \sigma_{o}, \sigma_{s}) = 1 - \alpha$ for
positive estimates and
$\Pr(\theta \leq 0 \given \that_{o}, \sigma_{o}, \sigma_{s}) = 1 - \alpha$ for
negative estimates. In a second step, the conflict between the skeptical prior
and the observed replication data is quantified, larger conflict indicating a
higher degree of replication success. For doing so, a prior predictive tail
probability
\begin{align*}
  p_{\text{Box}} =
  \begin{cases}
    1 - \Phi\left\{\that_{r}/(\sigma^{2}_{r} + \sigma^{2}_{s})\right\}
    & \text{if} ~ \that_{o} > 0 \\
   \Phi\left\{\that_{r}/(\sigma^{2}_{r} + \sigma^{2}_{s})\right\}
    & \text{if} ~ \that_{o} < 0 \\
    \end{cases}
\end{align*}
is computed and replication success at level $\alpha$ is declared if
$p_{\text{Box}} \leq \alpha$. The smallest level $\alpha$ at which replication
success is achieved is called the \emph{the skeptical $p$-value} $\ps$ and
replication success at level $\alpha$ is equivalent with $\ps \leq \alpha$
\citep[see][for more details on $\ps$]{Held2020, Held2021}. By applying some
algebraic manipulations to the condition $p_{\text{Box}} \leq \alpha$, one can
show that it is equivalent to the replication effect estimate $\that_{r}$
falling in the success region
\begin{align*}
  \SPs =
  \begin{cases}
    [\zalpha \surd\{\sigma^{2}_{r} +
  \frac{\sigma^{2}_{o}}{(z_{o}^{2}/\zalpha^{2}) - 1}\}, \infty)
    & \text{if} ~ \that_{o} > 0 \\
   (-\infty, -\zalpha \surd\{\sigma^{2}_{r} +
  \frac{\sigma^{2}_{o}}{(z_{o}^{2}/\zalpha^{2}) - 1}\}]
    & \text{if} ~ \that_{o} < 0. \\
    \end{cases}
\end{align*}

\section{The skeptical Bayes factor}
\label{sec:BFs}
\citet{Pawel2022b} modified the reverse-Bayes assessment of replication success
from \citet{Held2020} to use Bayes factors \citep{Jeffreys1961, Kass1995}
instead of tail probabilities as measures of evidence and prior data conflict.
The procedure assumes again the data model
$\that_{i} \given \theta \sim \Nor(\theta, \sigma^{2}_{i})$ for study
$i \in \{o, r\}$. In the first step the original data are used to contrast the
evidence for the point null hypothesis $H_{0} \colon \theta = 0$ relative to the
``skeptical'' alternative $H_{S} \colon \theta \sim \Nor(0, \sigma^{2}_{s})$
with the Bayes factor
\begin{align*}
  \BF_{0S}
  = \frac{f(\that_{o} \given H_{0})}{f(\that_{o} \given H_{S})}
  = \sqrt{1 + \sigma^{2}_{s}/\sigma^{2}_{o}} \, \exp\left\{-
  \, \frac{z_{o}^{2}}{2(1 + \sigma^{2}_{o}/\sigma^{2}_{s})}\right\}.
\end{align*}
where $z_{o} = \that/\sigma^{2}_{o}$. One then determines the sufficiently
skeptical prior variance $\sigma^{2}_{s}$ so that the Bayes factor is fixed to a
level $\gamma \in (0, 1)$ meaning that there is no longer evidence against the
null hypothesis at level $\gamma$. The sufficiently skeptical prior variance can
be computed by
\begin{align}
  \label{eq:ssv}
  \sigma^{2}_{s} &=
  \begin{cases}
    -\dfrac{\that_{o}^2}{q} - \sigma^{2}_{o} & ~~ \text{if} ~ -\dfrac{\that_o^2}{q} \geq \sigma^{2}_{o} \\
    \text{undefined} & ~~ \text{else}
  \end{cases} \\
  \text{where} ~ q &= \lw{-1} \left\{-\frac{z_o^2}{\gamma^2} \,
  \exp\left(-z_o^2\right)\right\}
\end{align}
with $\lw{-1}(\cdot)$ the branch of the
Lambert W function with $\text{W}(y) \leq -1$ for $y \in [-1/e, 0)$.

In a second step the conflict between the skeptical prior and the replication
data is quantified. To do so, the skeptic is contrasted to the ``advocacy''
alternative $H_{A} \colon \theta \sim \Nor(\that_{o}, \sigma^{2}_{o})$ which
represents the position of an advocate as the prior corresponds to the posterior
distribution based on the original data $\{\that_{o}, \sigma_{o}\}$ and a flat
prior for the effect size $\theta$. This is done by computing the Bayes factor
\begin{align*}
  \BF_{SA}
  = \frac{f(\that_{r} \given H_{S})}{f(\that_{r} \given H_{A})}
  = \sqrt{\frac{\sigma^{2}_{o} + \sigma^{2}_{r}}{\sigma^{2}_{s} + \sigma^{2}_{r}}}
  \, \exp\left[-\frac{1}{2}\left\{\frac{\that_{r}^{2}}{\sigma^{2}_{s} +
  \sigma^{2}_{r}} - \frac{(\that_{r} - \that_{o}^{2})}{\sigma^{2}_{o} +
  \sigma^{2}_{r}}\right\}\right]
\end{align*}
and replication success at level $\gamma$ is defined by $\BF_{SA} \leq \gamma$
as the data favor the advocate over the skeptic at a higher level than the
skeptic's initial objection to the null hypothesis. The smallest level $\gamma$
at which replication success is achievable is then called \emph{the skeptical
  Bayes factor} $\BFs$, and replication success at level $\gamma$ is equivalent
to $\BFs \leq \gamma$ \citep[see][for details on how to compute
$\BFs$]{Pawel2022b}. To derive the success region of the skeptical Bayes factor
one can apply algebraic manipulations to $\BF_{SA} \leq \gamma$, the condition
for replication success at level $\gamma$, which leads to
\begin{align}
  \label{eq:BFssuccess}
  S_{\scriptscriptstyle \BFs}
  = \begin{cases}
    (-\infty, -\sqrt{B} - M] \bigcup [\sqrt{B} - M, \infty) & \text{for} ~ \sigma^{2}_{s} < \sigma^{2}_{o} \\
    [\that_{o} -\{(\sigma^{2}_{o} + \sigma^{2}_{r})\log\gamma\}/\that_{o}, \infty)
    & \text{for} ~ \sigma^{2}_{s} = \sigma^{2}_{o}  \\
    [-\sqrt{B} - M, \sqrt{B} - M] & \text{for} ~ \sigma^{2}_{s} > \sigma^{2}_{o}
    \end{cases}
\end{align}
with
\begin{align*}
  B &= \left\{\frac{\that_{o}^{2}}{\sigma^{2}_{o} - \sigma^{2}_{s}} +
      2\log\left(\frac{\sigma^{2}_{o} + \sigma^{2}_{r}}{\sigma^{2}_{s} + \sigma^{2}_{r}}\right)
      - 2\log \gamma \right\}
      \frac{(\sigma^{2}_{s} + \sigma^{2}_{r})(\sigma^{2}_{o} + \sigma^{2}_{r})}{\sigma^{2}_{o}
       - \sigma^{2}_{s}} \\
  M &= \frac{\that_{o} (\sigma^{2}_{s} + \sigma^{2}_{r})}{\sigma^{2}_{o} - \sigma^{2}_{s}}
\end{align*}
and the sufficiently skeptical prior variance $\sigma^{2}_{s}$ computed
by~\eqref{eq:ssv}.

\section{Optimal number of sites}
\label{sec:multi}
The total cost of the design are $K = m(K_{c}n_{r} + K_{s})$ so that we can
write the number of sites $m$ for a given total cost as
\begin{align}
  \label{eq:msites}
  m = K (K_{c}n_{r} + K_{s})^{-1}.
\end{align}
We now want to minimize the predictive variance of the weighted average
$\that_{r*}$ which, for a balanced design, is given by
\begin{align}
  \label{eq:predvar}
  \sigma^{2}_{\scriptscriptstyle \that_{r*}}
  = \frac{\sigma^{2}_{r} + \tau^{2}}{m} + \frac{\tau^{2} + \sigma^{2}_{o}}{1 + 1/g}.
\end{align}
Plugging in~\eqref{eq:msites} into~\eqref{eq:predvar} and minimizing it with
respect to $n_{r}$, leads to the optimal sample size
\begin{align*}
  n_{r}^{*}
  = \frac{\lambda}{\tau} \, \sqrt{\frac{K_{s}}{K_{c}}}
\end{align*}
for a given cost ratio $K_{s}/K_{c}$.

\begin{figure}[!htb]
<< "sample-size-all-protzko", results = FALSE >>=
## ssd parameters
drange <- 0.2
tauAbs <- drange/(2*qnorm(p = 0.975))
taus <- c(0, tauAbs)
power <- 0.8
levelSig <- 0.025
levelSigMeta <- 0.025^2
levelPs <- levelSceptical(level = 0.025)
confLevel <- 0.9
margin <- 0.2
levelBFr <- 1/10
levelBFs <- 1/10
methodLabs <- c("'Two-trials rule'", "'Replication Bayes factor'",
                "'Meta-analysis'", "'Equivalence'",
                "'Skeptical' ~ italic(p) * '-value'",
                "'Skeptical Bayes factor'")
cols <- palette.colors(n = length(methodLabs), palette = "Okabe-Ito")
names(cols) <- methodLabs

## compute sample size for all studies with significant original study
dataSSD <- protzkolong %>%
    mutate(zo = dr/sqrt(vr)) %>%
    filter(Type == "Original")
resSSDlong <- lapply(X = dataSSD$Study, FUN = function(study) {
    study <- dataSSD[dataSSD$Study == study,]
    lapply(X = taus, FUN = function(tau) {
        ## design prior
        dprior <- designPrior(to = study$dr, so = sqrt(study$vr), tau = tau, type = "EB")
        ## compute standard errors
        sr2TR <- ssdSig(level = levelSig, dprior = dprior, power = power)$sr
        srMeta <- ssdMeta(level = levelSigMeta, dprior = dprior, power = power)$sr
        srBFr <- ssdBFr(level = levelBFr, dprior = dprior, power = power)$sr
        srEqu <- ssdEqu(level = 1 - confLevel, dprior = dprior, margin = margin,
                        power = power)$sr
        srPs <- ssdPs(level = levelPs, dprior = dprior, power = power)$sr
        srBFs <- ssdBFs(level = levelBFs, dprior = dprior, power = power)$sr
        ## compute type I errors
        dpriorH0 <- designPrior(to = study$dr, so = sqrt(study$vr), mu = 0,
                                sp = 0, tau = 0)
        if (!is.nan(sr2TR)) {
            t1e2TR <- porsSig(level = levelSig, dprior = dpriorH0, sr = sr2TR)
        } else t1e2TR <- NaN
        if (!is.nan(srMeta)) {
            t1eMeta <- porsMeta(level = levelSigMeta, dprior = dpriorH0, sr = srMeta)
        } else t1eMeta <- NaN
        if (!is.nan(srEqu)) {
            t1eEqu <- porsEqu(1 - confLevel, dprior = dpriorH0, margin = margin,
                               sr = srEqu)
        } else t1eEqu <- NaN
        if (!is.nan(srBFr)) {
            t1eBFr <- porsBFr(level = levelBFr, dprior = dpriorH0, sr = srBFr)
        } else t1eBFr <- NaN
        if (!is.nan(srPs)) {
            t1ePs <- porsPs(level = levelPs, dprior = dpriorH0, sr = srPs)
        } else t1ePs <- NaN
        if (!is.nan(srBFs)) {
            t1eBFs <- porsBFs(level = levelBFs, dprior = dpriorH0, sr = srBFs)
        } else t1eBFs <- NaN
        ## return results
        data.frame(study, tau = tau, sr_2TR = sr2TR, sr_Meta = srMeta,
                   sr_BFr = srBFr, sr_Equ = srEqu, sr_Ps = srPs, sr_BFs = srBFs,
                   t1e_2TR = t1e2TR, t1e_Meta = t1eMeta, t1e_Equ = t1eEqu,
                   t1e_BFr = t1eBFr, t1e_Ps = t1ePs, t1e_BFs = t1eBFs)
    }) %>%
        bind_rows()
}) %>%
    bind_rows() %>%
    rename(to = dr, vo = vr) %>%
    ## convert to long format
    pivot_longer(cols = c("sr_2TR", "sr_Meta", "sr_BFr", "sr_Equ", "sr_Ps",
                          "sr_BFs", "t1e_2TR",  "t1e_Meta", "t1e_Equ",
                          "t1e_BFr", "t1e_Ps", "t1e_BFs"), names_sep = "_",
                 names_to = c("res", "Method"))
resSSDt1e <- filter(resSSDlong, res == "t1e") %>%
    rename(t1e = value) %>%
    dplyr::select(-res)
resSSDsr <- filter(resSSDlong, res == "sr") %>%
    rename(sr = value) %>%
    dplyr::select(-res)
resSSD1 <- merge(resSSDt1e, resSSDsr) %>%
    mutate(so = sqrt(vo), c = so^2/sr^2,
           po = 1 - pnorm(abs(zo)),
           poFormat = ifelse(po >= 0.0001, paste('italic(p[o]) ~ "=" ~',
                                                 formatPval(p = po)),
                             'italic(p[o]) ~ "<" ~ 0.0001'))
@
<< "ssd-protzko", fig.height = 7 >>=
## plot relative sample size and corresponding type I error rates
resSSD2 <- resSSD1 %>%
    mutate(dp = case_when(tau == 0 ~ "tau == 0",
                          tau > 0 ~ paste("tau ==", round(tau, 2))),
           Methodlab = factor(Method,
                              levels = c("2TR", "BFr", "Meta", "Equ", "Ps", "BFs"),
                              labels = methodLabs),
           ## really ugly HACK to get correct spacing
           Studylab = paste0('atop(NA, atop(NA, atop(atop(NA, atop(bold("', Study,
                             '") ~ "(" * {', poFormat, '},  hat(theta)[italic(o)] ~ "=" ~',
                             round(to, 2), '* "," ~ sigma[italic("o")] ~ "=" ~',
                             round(so, 3), '* ")" )), NA)))'),
           c = ifelse(Method == "2TR" & abs(zo) <= qnorm(p = 1 - levelSig), NaN, c),
           t1e = ifelse(Method == "2TR" & abs(zo) <= qnorm(p = 1 - levelSig), NaN, t1e))
resSSD <- resSSD2 %>%
    mutate(Studylab = factor(Studylab,
                             levels = unique(resSSD2$Studylab)[
                                 rev(order(unique(abs(resSSD2$zo))))]))

## plot of relative sample size
cBreaks <- c(1/30, 1/10, 1/3, 1, 3, 10, 30, 100, 300)
plotA <- ggplot(data = resSSD, aes(x = Studylab, y = c, color = Methodlab,
                                   shape = dp)) +
    geom_hline(yintercept = 1, lty = 2, alpha = 0.3) +
    geom_vline(xintercept = seq(1.5, 15.5, 1), lty = 3, alpha = 0.1) +
    geom_linerange(aes(ymin = pmin(c, 1), ymax = pmax(c, 1),
                       color = Methodlab), position = position_dodge(width = 0.7),
                   show.legend = FALSE, alpha = 0.5, size = 0.4) +
    geom_point(position = position_dodge2(width = 0.7), size = 0.7) +
    labs(x = "Experiment",
         y = bquote("Relative sample size" ~ italic(c) == italic(n[r]/n[o])),
         color = "", shape = "") +
    guides(color = guide_legend(override.aes = list(size = 1.2)),
           shape = guide_legend(override.aes = list(size = 1.2))) +
    scale_color_manual(values = cols, labels = scales::parse_format()) +
    scale_y_log10(breaks = cBreaks, labels = formatBF(cBreaks)) +
    scale_x_discrete(labels = scales::label_parse()) +
    scale_shape_discrete(labels = scales::label_parse()) +
    theme_bw() +
    coord_flip(ylim = c(1/40, 350)) +
    theme(panel.grid.major.y = element_blank(),
          panel.grid.minor = element_blank(),
          legend.position = "top",
          axis.text.y = element_text(hjust = 0, size = 10),
          plot.margin = unit(c(0, 0, 0, 0), units = "mm"),
          legend.text.align = 0)

## plot of type I error rate
mysqrt_trans <- function() {
    trans_new("mysqrt",
              transform = base::sqrt,
              inverse = function(x) ifelse(x<0, 0, x^2),
              domain = c(0, Inf))
}
t1eNominal <- 0.025
t1eBks <- c(0, t1eNominal, 0.1, 0.25, 0.5, 1)
plotB <- ggplot(data = resSSD,
                aes(x = Studylab, y = t1e, color = Methodlab, shape = dp)) +
    geom_hline(yintercept = t1eNominal, lty = 2, alpha = 0.3) +
    geom_vline(xintercept = seq(1.5, 15.5, 1), lty = 3, alpha = 0.1) +
    geom_linerange(aes(ymin = pmin(t1eNominal, t1e), ymax = pmax(t1eNominal, t1e),
                       color = Methodlab), position = position_dodge(width = 0.7),
                   show.legend = FALSE, alpha = 0.5, size = 0.4) +
    geom_point(position = position_dodge2(width = 0.7), size = 0.7) +
    guides(color = guide_legend(override.aes = list(size = 1.2)),
           shape = guide_legend(override.aes = list(size = 1.2))) +
    scale_color_manual(values = cols, labels = scales::parse_format()) +
    scale_shape_discrete(labels = scales::label_parse()) +
    labs(x = "", y = "Type I error rate", color = "",
         shape = "") +
    scale_y_continuous(trans="mysqrt", breaks = t1eBks,
                       labels = scales::label_percent(accuracy = 0.1),
                       limits = c(0, 1)) +
    scale_x_discrete(labels = scales::label_parse()) +
    theme_bw() +
    coord_flip(ylim = c(0, 0.8)) +
    theme(panel.grid.major.y = element_blank(),
          panel.grid.minor = element_blank(),
          legend.position = "top",
          axis.text.y = element_blank(),
          axis.ticks.y = element_blank(),
          plot.margin = unit(c(0, 0, 0, 0), units = "mm"),
          legend.text.align = 0)

ggpubr::ggarrange(plotA, plotB, common.legend = TRUE,
                  align = "h", widths = c(2, 1))
@
\caption{The left plot shows the required relative sample size $c = n_r/n_o$ to
  achieve a target probability of replication success of
  $1 - \beta = \Sexpr{round(power*100, 2)}$\% (if possible). Replication success
  is defined through the two-trials rule at level $\alpha = \Sexpr{levelSig}$,
  replication Bayes factor at level $\gamma = 1/\Sexpr{1/levelBFr}$, fixed
  effects-meta analysis at level $\alpha = \Sexpr{sqrt(levelSigMeta)}^{2}$,
  effect size equivalence at level $\alpha = \Sexpr{1 - confLevel}$ with margin
  $\Delta = \Sexpr{margin}$, skeptical $p$-value at level
  $\alpha = \Sexpr{round(levelPs, 3)}$, and skeptical Bayes factor at level
  $\gamma = 1/\Sexpr{1/levelBFs}$ for data from the replication project by
  \citet{Protzko2020}. An adaptive shrinkage prior is used for the effect size
  $\theta$ either without ($\tau = 0$) or with between-study heterogeneity
  ($\tau = \Sexpr{round(taus[2], 2)}$). The right plot shows the type I error
  rate associated with the required sample size. Experiments are ordered (top to
  bottom) by their original one-sided $p$-value
  $p_{o} = 1 - \Phi(|\hat{\theta}_{o}|/\sigma_{o}$).}
\label{fig:ssd-all-shrink}
\end{figure}


\section{Sample size determination with adaptive shrinkage prior}
\label{sec:ssdprotzko}
Figure~\ref{fig:ssd-all-shrink} shows sample size determination for all studies
from the \citet{Protzko2020} project as in the main manuscript but using an
``adaptive shrinkage prior'' for the effect size $\theta$ where the variance of
the shrinkage prior is estimated by empirical Bayes. We see that the required
sample size increases for studies with large $p$-values compared to the analysis
based on a flat prior for $\theta$ as in the main manuscript, whereas it stays
about the same for studies with small $p$-values. This is because studies with
large $p$-values receive more shrinkage.

\newpage
%% Bibliography
%% -----------------------------------------------------------------------------
\bibliographystyle{apalikedoiurl}
\bibliography{../bibliography}


%% R sessionInfo for reproducibility
%% -----------------------------------------------------------------------------
<< "sessionInfo1", eval = reproducibility, results = "asis" >>=
## print R sessionInfo to see system information and package versions
## used to compile the manuscript (set Reproducibility = FALSE, to not do that)
cat("\\newpage \\section*{Computational details}")
@
<< "sessionInfo2", echo = reproducibility, results = reproducibility, size = "small" >>=
sessionInfo()
@


\end{document}
